var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = LLMCheatsheets","category":"page"},{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"API reference for LLMCheatsheets.","category":"page"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [LLMCheatsheets]","category":"page"},{"location":"api/#LLMCheatsheets.GitHubRepo","page":"API","title":"LLMCheatsheets.GitHubRepo","text":"GitHubRepo(url::String; paths = [\"src\", \"docs/src\", \"README.md\"],\n    file_types = [\".jl\", \".md\"])\n\nCreates a GitHubRepo object to represent a target GitHub repository.\n\nArguments\n\nurl::String: The URL of the GitHub repository.\npaths::Vector{String}: The folders and files to scan.\nfile_types::Vector{String}: The file types to accept in the scan.\n\nFields\n\nowner::String: The owner of the repository.\nname::String: The name of the repository.\nurl::String: The URL of the repository.\npaths::Vector{String}: The folders and files to scan.\nfile_types::Vector{String}: The file types to accept in the scan.\n\nNote: Files and folders are scanned recursively.\n\nKey methods: scan_github_path, create_cheatsheet, collect.\n\nscan_github_path is used to scan the repository and get the list of all relevant files.\ncreate_cheatsheet is used to create a cheatsheet from the repository.\ncollect is used to collect the repository content into a single string (no summarization).\n\nExample\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\nfiles = scan_github_path(repo)\n\nLet's create a cheatsheet and auto-save it to a file:\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\ncheatsheet = create_cheatsheet(repo; save_path = true)\n\nLet's collect all the files in the repository (eg, for LLM calls):\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\ncollated = collect(repo)\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.collect-Tuple{GitHubRepo}","page":"API","title":"Base.collect","text":"Base.collect(\n    repo::GitHubRepo;\n    verbose::Bool = true,\n    save_path::Union{Nothing, String, Bool} = nothing,\n    http_kwargs::NamedTuple = NamedTuple())\n\nScans a GitHub repository, downloads all the file contents, and combines them into a single large text document.\n\nThis function differs from create_cheatsheet in that it doesn't summarize or process the content into a cheatsheet, but instead concatenates the raw content of all files that match the specified criteria.\n\nNote: If you're getting rate limited by GitHub API, request a personal access token and set it as ENV[\"GITHUB_API_KEY\"] (raised your limit to 5000 requests per hour).\n\nArguments\n\nrepo::GitHubRepo: The repository to scan.\nverbose::Bool: Whether to print verbose output.\nsave_path: If provided, saves the collated content to this file path. If true, the content is saved to a subdirectory called llm-cheatsheets in the current working directory.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function influencing the HTTP requests.\n\nReturns\n\nString: The collated content of all scanned files and their contents in the repository.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.collate_files-Tuple{AbstractVector{<:AbstractDict}}","page":"API","title":"LLMCheatsheets.collate_files","text":"collate_files(file_contents::AbstractVector{<:AbstractDict})\n\nCollates the file contents into a single string.\n\nArguments\n\nfile_contents::AbstractVector{<:AbstractDict}: The contents of the files in the repository. Requires :name and :content fields.\n\nReturns\n\nString: A string with the concatenated file names and contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.create_cheatsheet-Tuple{GitHubRepo, AbstractVector{<:AbstractDict}}","page":"API","title":"LLMCheatsheets.create_cheatsheet","text":"create_cheatsheet(\n    repo::GitHubRepo, file_contents::AbstractVector{<:AbstractDict};\n    model = \"gpt4o\", special_instructions::AbstractString = \"None.\n\n\",         costtracker::Union{Nothing, Threads.Atomic{<:Real}} = nothing,         verbose::Bool = true, savepath::Union{Nothing, String, Bool} = nothing,         http_kwargs::NamedTuple = NamedTuple())\n\ncreate_cheatsheet(repo::GitHubRepo;\n    model = \"gpt4o\", cost_tracker::Union{Nothing, Threads.Atomic{<:Real}} = Threads.Atomic{Float64}(0.0),\n    special_instructions::AbstractString = \"None.\n\n\",         verbose::Bool = true, savepath::Union{Nothing, String} = nothing,         httpkwargs::NamedTuple = NamedTuple())\n\nCreates a cheatsheet for the given GitHub repository and file summaries.\n\nNote: If you're getting rate limited by GitHub API, request a personal access token and set it as ENV[\"GITHUB_API_KEY\"] (raised your limit to 5000 requests per hour).\n\nArguments\n\nrepo::GitHubRepo: The repository to create a cheatsheet for.\nfile_contents::AbstractVector{<:AbstractDict}: The file contents or the summaries of the files in the repository. If not provided, the repository is scanned and the file summaries are created.\nmodel::String: The model to use for the LLM call.\nspecial_instructions::AbstractString: Special instructions for the AI to tweak the output.\ncost_tracker::Union{Nothing, Threads.Atomic{<:Real}}: A tracker to record the cost of the LLM calls.\nverbose::Bool: Whether to print verbose output.\nsave_path::Union{Nothing, String, Bool}: The path to save the cheatsheet to. If true, the cheatsheet is auto-saved to a subdirectory called llm-cheatsheets in the current working directory.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function influencing the HTTP requests.\n\nReturns\n\nString: The content of the cheatsheet.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.github_api-Tuple{String}","page":"API","title":"LLMCheatsheets.github_api","text":"github_api(url::String; api_key::String=GITHUB_API_KEY, retries::Int=10)\n\nMakes a GET request to the GitHub API with the specified URL.\n\nArguments\n\nurl::String: The GitHub API endpoint URL.\napi_key::String: The GitHub API key. Defaults to the global GITHUBAPIKEY.\nretries::Int: The number of retry attempts for the request. Defaults to 10.\nkwargs: Additional keyword arguments to pass to HTTP.get.\n\nReturns\n\nHTTP.Response: The response from the GitHub API.\nJSON3.Object: The parsed JSON response body.\n\nThrows\n\nHTTP.ExceptionRequest.StatusError: If the request fails after all retries.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.scan_github_path-Tuple{GitHubRepo, String}","page":"API","title":"LLMCheatsheets.scan_github_path","text":"scan_github_path(repo::GitHubRepo, path::String; verbose = true,\n    http_kwargs::NamedTuple = NamedTuple())\n\nscan_github_path(repo::GitHubRepo; verbose = true,\n    http_kwargs::NamedTuple = NamedTuple())\n\nScans a specific path in a GitHub repository and returns a list of files it contains that meet the criteria in repo. Scans any nested folders recursively.\n\nNote: If you're getting rate limited by GitHub, set the API key in ENV[\"GITHUB_API_KEY\"].\n\nArguments\n\nrepo::GitHubRepo: The repository to scan.\npath::String: The path to scan in the repository. If path is not provided, it will scan all paths in the repo object.\nverbose::Bool: Whether to print verbose output.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to github_api.\n\nReturns\n\nVector{JSON3.Object}: A list of files and folders in the specified path.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.summarize_file-Tuple{AbstractDict}","page":"API","title":"LLMCheatsheets.summarize_file","text":"summarize_file(file_info::AbstractDict; model = \"gpt4o\",\n    special_instructions::AbstractString = \"None.\n\n\",         costtracker::Union{Nothing, Threads.Atomic{<:Real}} = nothing,         verbose::Bool = true, httpkwargs::NamedTuple = NamedTuple())\n\nSummarizes the content of a file in a GitHub repository.\n\nArguments\n\nfile_info::AbstractDict: The file information from the GitHub API. Requires :name and :download_url fields.\nmodel::String: The model to use for the LLM call.\nspecial_instructions::AbstractString: Special instructions for the AI to tweak the output.\ncost_tracker::Union{Nothing, Threads.Atomic{<:Real}}: A tracker to record the cost of the LLM calls.\nverbose::Bool: Whether to print verbose output.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function.\n\nReturns\n\nDict: A dictionary with the file name (:file field), the content (:content field), and the type (:type field).\n\n\n\n\n\n","category":"method"},{"location":"#LLMCheatsheets.jl-Documentation","page":"Home","title":"LLMCheatsheets.jl Documentation","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"LLMCheatsheets.jl is a Julia package designed to make it easy and instant to teach AI about new packages and repositories by creating instant cheatsheets from GitHub repositories. This tool aims to bridge the gap between human-readable documentation and AI-friendly knowledge representation.","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Instant cheatsheet generation from GitHub repositories\nAI-friendly knowledge representation\nEasy integration with language models and AI assistants\nSupport for various Julia packages and repositories","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install LLMCheatsheets.jl, use the Julia package manager and the repo URL (it's not registered yet):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url = \"https://github.com/svilupp/LLMCheatsheets.jl\")","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here's a basic example of how to use LLMCheatsheets.jl to create a cheatsheet for a GitHub repository.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LLMCheatsheets\n\nrepo = GitHubRepo(\"https://github.com/svilupp/PromptingTools.jl\")\ncreate_cheatsheet(repo; save_path = true);","category":"page"},{"location":"","page":"Home","title":"Home","text":"With save_path = true, the cheatsheet will be saved to folder llm-cheatsheets in the current working directory.","category":"page"},{"location":"","page":"Home","title":"Home","text":"What happens behinds the scenes:","category":"page"},{"location":"","page":"Home","title":"Home","text":"The repository is scanned to find all the relevant files (that match repo.paths and repo.file_types).\nEach file is summarized using an LLM.\nThe summaries are used to generate a cheatsheet.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a low-level interface to generate the files individually and process them yourself, see examples/create_for_promptingtools.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Sometimes you might want to just download the files without summarizing them. You can do that with collect function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"files_str = collect(repo)","category":"page"},{"location":"","page":"Home","title":"Home","text":"files_str will be a string with all scanned files concatenated together, eg, to use in ChatGPT or claude.ai.","category":"page"},{"location":"","page":"Home","title":"Home","text":"By default, the files scanned and downloaded are repo.paths and repo.file_types, respectively.","category":"page"},{"location":"#Advanced-Usage","page":"Home","title":"Advanced Usage","text":"","category":"section"},{"location":"#Using-a-different-LLM","page":"Home","title":"Using a different LLM","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can use a different LLM by passing the model argument to the functions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"create_cheatsheet(repo; save_path = true, model = \"gpt4om\")","category":"page"},{"location":"#Using-PromptingTools.jl-to-Ask-Questions","page":"Home","title":"Using PromptingTools.jl to Ask Questions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can simply export also ai* functions from PromptingTools.jl to use them with LLMCheatsheets.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LLMCheatsheets\n# Re-export aigenerate, pprint from PromptingTools\nusing LLMCheatsheets: aigenerate, pprint\n# Or import PromptingTools directly\n# using PromptingTools\n\nrepo = GitHubRepo(\"https://github.com/svilupp/PromptingTools.jl\")\nfiles_str = collect(repo)\n\nmsg = aigenerate(\"What is the function for create prompts?\\n Check these files:\\n$files_str\")\npprint(msg)","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For more information about using LLMCheatsheets.jl, please refer to the documentation.","category":"page"},{"location":"#Issues-and-Support","page":"Home","title":"Issues and Support","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you encounter any issues or have questions, please open an issue on the GitHub repository.","category":"page"}]
}
