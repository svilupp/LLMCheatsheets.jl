var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = LLMCheatsheets","category":"page"},{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"API reference for LLMCheatsheets.","category":"page"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [LLMCheatsheets]","category":"page"},{"location":"api/#LLMCheatsheets.GitHubRepo","page":"API","title":"LLMCheatsheets.GitHubRepo","text":"GitHubRepo(url::String; paths = [\"src\", \"docs/src\", \"README.md\"],\n    file_types = [\".jl\", \".md\"])\n\nCreates a GitHubRepo object to represent a target GitHub repository.\n\nArguments\n\nurl::String: The URL of the GitHub repository.\npaths::Vector{String}: The folders and files to scan.\nfile_types::Vector{String}: The file types to accept in the scan.\n\nFields\n\nowner::String: The owner of the repository.\nname::String: The name of the repository.\nurl::String: The URL of the repository.\npaths::Vector{String}: The folders and files to scan.\nfile_types::Vector{String}: The file types to accept in the scan.\n\nNote: Files and folders are scanned recursively.\n\nKey methods: scan_github_path, create_cheatsheet, collect.\n\nscan_github_path is used to scan the repository and get the list of all relevant files.\ncreate_cheatsheet is used to create a cheatsheet from the repository.\ncollect is used to collect the repository content into a single string (no summarization).\n\nExample\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\nfiles = scan_github_path(repo)\n\nLet's create a cheatsheet and auto-save it to a file:\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\ncheatsheet = create_cheatsheet(repo; save_path = true)\n\nLet's collect all the files in the repository (eg, for LLM calls):\n\nrepo = GitHubRepo(\"https://github.com/username/repository\")\ncollated = collect(repo)\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.collect-Tuple{GitHubRepo}","page":"API","title":"Base.collect","text":"Base.collect(\n    repo::GitHubRepo;\n    verbose::Bool = true,\n    save_path::Union{Nothing, String, Bool} = nothing,\n    ntasks::Int = 0,\n    http_kwargs::NamedTuple = NamedTuple())\n\nScans a GitHub repository, downloads all the file contents, and combines them into a single large text document.\n\nThis function differs from create_cheatsheet in that it doesn't summarize or process the content into a cheatsheet, but instead concatenates the raw content of all files that match the specified criteria.\n\nNote: If you're getting rate limited by GitHub API, request a personal access token and set it as ENV[\"GITHUB_API_KEY\"] (raised your limit to 5000 requests per hour).\n\nArguments\n\nrepo::GitHubRepo: The repository to scan.\nverbose::Bool: Whether to print verbose output.\nsave_path: If provided, saves the collated content to this file path. If true, the content is saved to a subdirectory called llm-cheatsheets in the current working directory.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function influencing the HTTP requests.\nntasks::Int: The number of tasks to use for the asynchronous processing. If 0, the number of tasks is set to the asyncmap default.\n\nReturns\n\nString: The collated content of all scanned files and their contents in the repository.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.collate_files-Tuple{AbstractVector{<:AbstractDict}}","page":"API","title":"LLMCheatsheets.collate_files","text":"collate_files(file_contents::AbstractVector{<:AbstractDict})\n\nCollates the file contents into a single string.\n\nArguments\n\nfile_contents::AbstractVector{<:AbstractDict}: The contents of the files in the repository. Requires :name and :content fields.\n\nReturns\n\nString: A string with the concatenated file names and contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.create_cheatsheet-Tuple{GitHubRepo, AbstractVector{<:AbstractDict}}","page":"API","title":"LLMCheatsheets.create_cheatsheet","text":"create_cheatsheet(\n    repo::GitHubRepo, file_contents::AbstractVector{<:AbstractDict};\n    model = \"gpt4o\", special_instructions::AbstractString = \"None.\n\n\",         template::Symbol = :CheatsheetCreator,         costtracker::Union{Nothing, Threads.Atomic{<:Real}} = nothing,         verbose::Bool = true, savepath::Union{Nothing, String, Bool} = nothing,         http_kwargs::NamedTuple = NamedTuple())\n\ncreate_cheatsheet(repo::GitHubRepo;\n    model = \"gpt4o\", cost_tracker::Union{Nothing, Threads.Atomic{<:Real}} = Threads.Atomic{Float64}(0.0),\n    special_instructions::AbstractString = \"None.\n\n\",         template::Symbol = :CheatsheetCreator,         verbose::Bool = true, savepath::Union{Nothing, String} = nothing,         ntasks::Int = 0,         httpkwargs::NamedTuple = NamedTuple())\n\nCreates a cheatsheet for the given GitHub repository and file summaries.\n\nNote: If you're getting rate limited by GitHub API, request a personal access token and set it as ENV[\"GITHUB_API_KEY\"] (raised your limit to 5000 requests per hour).\n\nArguments\n\nrepo::GitHubRepo: The repository to create a cheatsheet for.\nfile_contents::AbstractVector{<:AbstractDict}: The file contents or the summaries of the files in the repository. If not provided, the repository is scanned and the file summaries are created.\nmodel::String: The model to use for the LLM call.\nspecial_instructions::AbstractString: Special instructions for the AI to tweak the output.\ntemplate::Symbol: The template to use for the cheatsheet creation.\ncost_tracker::Union{Nothing, Threads.Atomic{<:Real}}: A tracker to record the cost of the LLM calls.\nverbose::Bool: Whether to print verbose output.\nsave_path::Union{Nothing, String, Bool}: The path to save the cheatsheet to. If true, the cheatsheet is auto-saved to a subdirectory called llm-cheatsheets in the current working directory.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function influencing the HTTP requests.\nntasks::Int: The number of tasks to use for the asynchronous processing. If 0, the number of tasks is set to the asyncmap default.\n\nReturns\n\nString: The content of the cheatsheet.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.github_api-Tuple{String}","page":"API","title":"LLMCheatsheets.github_api","text":"github_api(url::String; api_key::String=GITHUB_API_KEY, retries::Int=10)\n\nMakes a GET request to the GitHub API with the specified URL.\n\nArguments\n\nurl::String: The GitHub API endpoint URL.\napi_key::String: The GitHub API key. Defaults to the global GITHUBAPIKEY.\nretries::Int: The number of retry attempts for the request. Defaults to 10.\nkwargs: Additional keyword arguments to pass to HTTP.get.\n\nReturns\n\nHTTP.Response: The response from the GitHub API.\nJSON3.Object: The parsed JSON response body.\n\nThrows\n\nHTTP.ExceptionRequest.StatusError: If the request fails after all retries.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.scan_github_path-Tuple{GitHubRepo, String}","page":"API","title":"LLMCheatsheets.scan_github_path","text":"scan_github_path(repo::GitHubRepo, path::String; verbose = true,\n    http_kwargs::NamedTuple = NamedTuple())\n\nscan_github_path(repo::GitHubRepo; verbose = true,\n    http_kwargs::NamedTuple = NamedTuple())\n\nScans a specific path in a GitHub repository and returns a list of files it contains that meet the criteria in repo. Scans any nested folders recursively.\n\nNote: If you're getting rate limited by GitHub, set the API key in ENV[\"GITHUB_API_KEY\"].\n\nArguments\n\nrepo::GitHubRepo: The repository to scan.\npath::String: The path to scan in the repository. If path is not provided, it will scan all paths in the repo object.\nverbose::Bool: Whether to print verbose output.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to github_api.\n\nReturns\n\nVector{JSON3.Object}: A list of files and folders in the specified path.\n\n\n\n\n\n","category":"method"},{"location":"api/#LLMCheatsheets.summarize_file-Tuple{AbstractDict}","page":"API","title":"LLMCheatsheets.summarize_file","text":"summarize_file(file_info::AbstractDict; model = \"gpt4o\",\n    special_instructions::AbstractString = \"None.\n\n\",         costtracker::Union{Nothing, Threads.Atomic{<:Real}} = nothing,         verbose::Bool = true, httpkwargs::NamedTuple = NamedTuple())\n\nSummarizes the content of a file in a GitHub repository.\n\nArguments\n\nfile_info::AbstractDict: The file information from the GitHub API. Requires :name and :download_url fields.\nmodel::String: The model to use for the LLM call.\nspecial_instructions::AbstractString: Special instructions for the AI to tweak the output.\ncost_tracker::Union{Nothing, Threads.Atomic{<:Real}}: A tracker to record the cost of the LLM calls.\nverbose::Bool: Whether to print verbose output.\nhttp_kwargs::NamedTuple: Additional keyword arguments to pass to the github_api function.\n\nReturns\n\nDict: A dictionary with the file name (:name field), the content (:content field), and the type (:type field).\n\n\n\n\n\n","category":"method"},{"location":"#LLMCheatsheets.jl-Documentation","page":"Home","title":"LLMCheatsheets.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"LLMCheatsheets.jl is a Julia package that makes it easy and instant to teach AI models about new packages and repositories by creating cheatsheets from GitHub repositories. This tool bridges the gap between human-readable documentation and AI-friendly knowledge representation, allowing for seamless integration with language models and AI assistants.","category":"page"},{"location":"","page":"Home","title":"Home","text":"By default, we take a subset of the folders and files in the provided repository and summarize them using an LLM into a single cheatsheet.","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Instant cheatsheet generation from GitHub repositories.\nAI-friendly knowledge representation by summarizing code and documentation (or just collate all the raw files into a single string).\nEasy integration with language models and AI assistants (just copy the cheatsheet into your prompt).\nSupport for any package and easier to start than Retrieval Augmented Generation (RAG).","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install LLMCheatsheets.jl, use the Julia package manager and the repo URL (it's not registered yet):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url = \"https://github.com/svilupp/LLMCheatsheets.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"[!TIP] If you encounter rate limits when accessing the GitHub API, you can set up a personal access token and set it as an environment variable GITHUB_API_KEY to increase your request limit to 5000 per hour.","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here's a basic example of how to use LLMCheatsheets.jl to create a cheatsheet for a GitHub repository.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LLMCheatsheets\n\nrepo = GitHubRepo(\"https://github.com/svilupp/PromptingTools.jl\")\ncreate_cheatsheet(repo; save_path = true);","category":"page"},{"location":"","page":"Home","title":"Home","text":"With save_path = true, the cheatsheet will be saved to folder llm-cheatsheets in the current working directory.","category":"page"},{"location":"","page":"Home","title":"Home","text":"What happens behind the scenes:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Scanning the Repository: The repository is scanned to find all relevant files that match repo.paths and repo.file_types.\nSummarizing Files: Each file is summarized using an LLM.\nGenerating Cheatsheet: The summaries are combined to generate a comprehensive cheatsheet.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a low-level interface to generate the files individually and process them yourself, see examples/create_for_promptingtools.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Sometimes you might want to just download the files without summarizing them. You can do that with collect function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"files_str = collect(repo)","category":"page"},{"location":"","page":"Home","title":"Home","text":"files_str will be a string with all scanned files concatenated together.  To use it in ChatGPT or Claude.ai, use clipboard functionality to copy it to clipboard - files_str|>clipboard.","category":"page"},{"location":"","page":"Home","title":"Home","text":"By default, the files scanned and downloaded are repo.paths and repo.file_types, respectively.","category":"page"},{"location":"#Advanced-Usage","page":"Home","title":"Advanced Usage","text":"","category":"section"},{"location":"#Customizing-scanned-paths-and-file-types","page":"Home","title":"Customizing scanned paths and file types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"By default, repo.paths includes [\"src\", \"docs/src\", \"README.md\"], and repo.file_types includes [\".jl\", \".md\"]. You can customize these when creating the GitHubRepo object:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Eg, adding a folder examples and .txt files to customize what we will summarize:","category":"page"},{"location":"","page":"Home","title":"Home","text":"repo = GitHubRepo(\"https://github.com/username/repository\"; paths = [\"examples\", \"README.md\"], file_types = [\".jl\", \".md\", \".txt\"])","category":"page"},{"location":"#Using-a-different-LLM","page":"Home","title":"Using a different LLM","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can use a different LLM by passing the model argument to the functions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"create_cheatsheet(repo; save_path = true, model = \"gpt4om\")","category":"page"},{"location":"#Adding-Special-Instructions","page":"Home","title":"Adding Special Instructions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can provide special instructions to guide the AI in generating the cheatsheet:","category":"page"},{"location":"","page":"Home","title":"Home","text":"create_cheatsheet(repo; special_instructions = \"Focus on the data structures and their interactions.\")","category":"page"},{"location":"#Using-PromptingTools.jl-to-Ask-Questions","page":"Home","title":"Using PromptingTools.jl to Ask Questions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can simply export also ai* functions from PromptingTools.jl to use them with LLMCheatsheets.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LLMCheatsheets\n# Re-export aigenerate, pprint from PromptingTools\nusing LLMCheatsheets: aigenerate, pprint\n# Or import PromptingTools directly\n# using PromptingTools\n\nrepo = GitHubRepo(\"https://github.com/svilupp/PromptingTools.jl\"; paths = [\"docs/src\", \"README.md\"])\nfiles_str = collect(repo)\n\nmsg = aigenerate(\"Read through these files: $(files_str)\\n\\nAnswer the question: What is the function for creating prompt templates?\")\npprint(msg)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function for creating prompt templates in the `PromptingTools.jl` package is `create_template`. This function allows you to define a prompt with placeholders and save it for later use. The syntax is:\n\n```julia\ncreate_template(; user=<user prompt>,\nsystem=<system prompt>, load_as=<template name>)\n```\n\nThis function generates a vector of messages, which you can use directly in the `ai*` functions. If you provide the `load_as` argument, it will also register the template in the template store,\nallowing you to access it later using its name.","category":"page"},{"location":"#Frequently-Asked-Questions","page":"Home","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"#I-am-getting-rate-limited-by-LLM-providers","page":"Home","title":"I am getting rate-limited by LLM providers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you are getting rate-limited by LLM providers, you can decrease the number of concurrent summarization tasks in create_cheatsheet by setting a lower number like ntasks=5 or ntasks=2 (depends on your API tier).","category":"page"},{"location":"#I-am-getting-rate-limited-by-GitHub-API","page":"Home","title":"I am getting rate-limited by GitHub API","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Set up a personal access token and set it as ENV[\"GITHUB_API_KEY\"]. It will be automatically loaded into a variable LLMCheatsheets.GITHUB_API_KEY.","category":"page"},{"location":"#How-do-I-set-up-a-personal-access-token-for-GitHub-API?","page":"Home","title":"How do I set up a personal access token for GitHub API?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can set up a personal access token for GitHub API by following these steps:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Go to your GitHub settings.\nClick on \"Personal access tokens\".\nClick on \"Generate new token\".","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then you can set it as ENV[\"GITHUB_API_KEY\"] or LLMCheatsheets.GITHUB_API_KEY.","category":"page"}]
}
